\documentclass{exam}
\usepackage{amsmath, amsfonts}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[super]{nth}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}


\input{../macros}
%\renewcommand{\hide}[1]{#1}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}

\pagestyle{headandfoot}

%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%
\newcommand{\duedate}{10.05.19 (10:00 am)}
\newcommand{\due}{{\bf This assignment is due on \duedate.} }
\firstpageheader
{Due: \duedate \\ Points: 2}
{{\bf\lecture}\\ \assignment{2}}
{\lectors\\ \semester}

\runningheader
{Due: \duedate}
{\assignment{2}}
{\semester}
%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%

\firstpagefooter
{}
{\thepage}
{}

\runningfooter
{}
{\thepage}
{}

\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}
	\gccs
	The goal of this exercise is to get you familiar with a simple supervised machine learning algorithm for classification and the influence of its hyperparameters on the generalization performance. You will implement the k-nearest neighbor (KNN) classifier, which is a non-parametric model, i.e. it does not make any assumptions about the data generating distribution.
	
	\bigskip
	
	\noindent All tasks include the submission of some results (besides the code).
	To submit these results, please submit a PDF with all the results and your name(s).
	
	\noindent We provide a simple Makefile which you can use to install all packages listed in your requirements file (\texttt{make init}).
	
	
	\begin{questions}
		
		
		\titledquestion{Implementing your own KNN classifier}[1]
		
		Consider the classification of the examples in the \href{https://archive.ics.uci.edu/ml/datasets/Iris}{Iris Flower Dataset}, which consists of 3 species/classes (\textit{Iris setosa, Iris virginica and Iris versicolor}) and each example has 4 features (\textit{sepal lenght, sepal width, petal length, petal width}). There is a total of 150 examples.

		In a nutshell, KNN assigns a class to an unseen example based on the majority vote of the K most similar instances. We will use two distance metrics as a similarity metric in this exercise: 
		\begin{itemize}
			\item Euclidian distance $d_E(x, x^{\prime}) = \sqrt{\sum_{i=1}^n{(x_i - x_i^{\prime})^2}}$
			\item Manhattan distance $d_M(x, x^{\prime}) = \sum_{i=1}^n{\lvert x_i - x_i^{\prime} \rvert}$
		\end{itemize}
		 where $n$ is the number of features. When a new test example $x$ is fed to the KNN classifier it performs the two following steps:
		
		\begin{itemize}
			\item Computes the distance $d$ between this example and all the examples in the training set.
			\item For each class $j$ estimate the conditional probability for the example being assigned to that class based on the K closest examples: $$P(y=j|X=x) = \frac{1}{K}\sum_{i\in A}\mathbb{I}(y^{(i)}=j),$$where $A$ is the set of K closest training examples and $\mathbb{I}$ is the indicator function. This way, the KNN classifier assigns to $x$ the class with the highest probability.

		\end{itemize}	
		
		Your first task is to implement by yourself the KNN algorithm in Python so it can learn to classify the examples in the Iris Dataset. For starters select a random value for K as the default one. It should be possible to call your program as \texttt{python knn\_classifier.py [K value] -d [distance metric]}.
			
		Run the code for all three different similarity metrics and report their results in the pdf.
		
		\titledquestion{Tuning the hyperparameters of your KNN classifier}[1]
		
		Now we want to tune the value of $K$ and the distance metric $d$ using 10-fold cross-validation as a cost metric. 
		Provide in the pdf what type of hyperparameters these two are.
		You have to determine the range of values that K will take $[K_{min}, K_{max}]$ based on the size of your training dataset and plot the accuracy of your model depending on the K value (similar to the plot in slide 12 of Lecture 1) for each distance metric type. 
		It should be possible to call your program as \texttt{python exhaustive\_search.py}. After that 2 plots will be generated (one for each distance metric).
		
		Afterwards you should report in the pdf the optimal value(s) of $K$ and $d$ that you find by this exhaustive search (its called exhaustive since you evaluate all possible configurations in your design space), as well as the accuracy of the classifier on the test set with these values. 
		
		In the end, you should write a short justification about the chosen range for K and interpret why the cross-validation accuracy goes down for larger/smaller values of K than the optimal one(s).

		%[HINT: You can also use the KNN implementation from sklearn in this exercise.]
		
		\titledquestion{Feedback}[Bonus: 1]
		For each question in this assignment, state:
		\begin{itemize}
			\item How long you worked on it.
			\item What you learned.
			\item Anything you would improve in this question if you were teaching the course.
		\end{itemize}
	\end{questions}
	
	\noindent
	Submit your solution for the tasks by uploading a PDF to your groups BitBucket repository. The PDF has to include the name of the submitter(s). Teams of at most $2$ students are allowed.
\end{document}
