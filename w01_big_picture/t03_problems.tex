
\input{../latex_main/main.tex}



\title[AutoML: Problem]{AutoML: Overview of Problems}
\author[Marius Lindauer]{Bernd Bischl \and Frank Hutter \and Lars Kotthoff \and \underline{Marius Lindauer}}
\institute{}
\date{}



% \AtBeginSection[] % Do nothing for \section*
% {
%   \begin{frame}{Outline}
%     \bigskip
%     \vfill
%     \tableofcontents[currentsection]
%   \end{frame}
% }

\begin{document}
	
	\maketitle
	


%----------------------------------------------------------------------
\begin{frame}[c]{Hyperparameters of an SVM}

\centering
\includegraphics[width=0.7\textwidth]{images/sklearn_svm_doc.png}

\end{frame}
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Hyperparameter Optimization}

\begin{block}{Definition}
	Let 
	\begin{itemize}
		\item $\conf$ be the hyperparameters of an ML algorithm $\algo$ with domain $\pcs$,
		\pause
		\item $\dataset_{opt}$ be a training set which is split into $\dataset_{train}$ and $\dataset_{valid}$ 
		\pause
		\item $\loss(\algo_\conf, \dataset_{train}, \dataset_{valid})$ denote the loss of $\algo_\conf$ trained on $\dataset_{train}$ and evaluated on $\dataset_{valid}$.
	\end{itemize}
	\pause
	The \emph{hyper-parameter optimization (HPO)} problem is to find a hyper-parameter configuration that minimizes this loss:
	\begin{equation}
	\conf^* \in \argmin_{\conf \in \pcs} \loss(\algo_\conf, \dataset_{train}, \dataset_{valid}) \nonumber  
	\end{equation}
\end{block}

\pause
Remarks: 

\begin{itemize}
	\item $\argmin$ returns a set of optimal points of a given function. It suffices to find one element of this set and thus we use $\in$ instead of $=$.
	\pause
	\item Sometimes, we want to optimize for different metrics, instead of one
	\begin{itemize}
		\item[$\leadsto$] multi-objective optimization and Pareto fronts
	\end{itemize}
\end{itemize}

\end{frame}
%-----------------------------------------------------------------------
%----------------------------------------------------------------------
\begin{frame}[c]{Choosing an Algorithm}

\begin{itemize}
	\item Over the years, many ML-algorithms were proposed
	\pause
	\item Most of these still have a reason for existence
	\pause
	\item Examples for classification:
	\begin{itemize}
		\item logistic regression
		\item k-nearest neighbor
		\item naive bayes
		\item support vector machine
		\item decision tree
		\item random forest
		\item gradient boosting
		\item multi-layer perceptron
		\item residual networks
		\item ...
	\end{itemize}
	\pause
	\item \lit{\href{http://jmlr.org/papers/volume15/delgado14a/delgado14a.pdf}{Fern\'andez-Delgado et al. 2015}} studied $179$ classifiers on $121$ datasets
	\pause
	\item In practice, we actually want to jointly choose\newline the best ML-algorithm and its hyperparameters
\end{itemize}


\end{frame}
%-----------------------------------------------------------------------
%----------------------------------------------------------------------
\begin{frame}[c]{CASH: Combined Algorithm Selection and\newline Hyperparameter Optimization}

\begin{block}{Definition}
	Let
	\begin{itemize}
		\item \alert{$\algos = \{\algo_1, \algo_2, \ldots, \algo_k\}$ be a set of algorithms (a.k.a. portfolio)}
		\item $\pcs$ be a set of hyperparameters of each machine learning algorithm $\algo_i$
		\item $\dataset_{opt}$ be a training set which is split into $\dataset_{train}$ and $\dataset_{valid}$ 
		\item $\loss(\algo_\conf, \dataset_{train}, \dataset_{valid})$ denote the loss of $\algo_\conf$ trained on $\dataset_{train}$ and evaluated on $\dataset_{valid}$.
	\end{itemize}
	we want to find \alert{the best combination of algorithm $\algo \in \mathbf{A}$ and its hyperparameter configuration $\conf \in \pcs$} minimizing:
	\begin{equation}
	(\algo^*, \conf^*) \in \argmin_{\algo \in \algos, \conf \in \pcs} \loss(\algo_\conf, \dataset_{train}, \dataset_{valid}) \nonumber
	\end{equation}
\end{block}

\end{frame}
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Architectures of Neural Networks}

\begin{columns}
	\column{0.5\textwidth}
	
	\begin{itemize}
		\item Many architecture were proposed
		\item Differences in 
		\begin{itemize}
			\item Depth
			\item Resolution
			\item Width
			\item Operators
			\item Connections
			\item ...
		\end{itemize}
	\end{itemize}
	
	\column{0.5\textwidth}
	
	\centering
	\includegraphics[width=0.7\textwidth]{images/overview_achitecture_perf.PNG}\newline
	on Imagenet~\lit{\href{https://arxiv.org/pdf/1605.07678.pdf}{Canzian et al. 2017}}
	
\end{columns}

\pause
\begin{itemize}
	\item Already on a single dataset such as ImageNet,\\ it is not obvious which architeture to choose
	\pause
	\item For other datasets, you might need different architectures\\ to achieve top-performance
	
	\pause
	\begin{itemize}
		\item For similar datasets, you might use scaled versions of known architectures (e.g., CIFAR10 and Imagenet)
	\end{itemize}
\end{itemize}

\end{frame}
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Neural Architecture Search (NAS)}

\begin{block}{Definition}
	Let 
	\begin{itemize}
		\item $\conf$ be \alert{an architecture for a deep neural network $\nn$} with domain $\pcs$,
		\item $\dataset_{opt}$ be a training set which is split into $\dataset_{train}$ and $\dataset_{valid}$ 
		\item $\loss(\algo_\conf, \dataset_{train}, \dataset_{valid})$ denote the loss of $\nn_\conf$ trained on $\dataset_{train}$ and evaluated on $\dataset_{valid}$.
	\end{itemize}
	The \emph{neural architecture search (NAS)} problem is to find an architecture that minimizes this loss:
	\begin{equation}
	\conf^* \in \argmin_{\conf \in \pcs} \loss(\algo_\conf, \dataset_{train}, \dataset_{valid}) \nonumber  
	\end{equation}
\end{block}

\pause
\smallskip
Remark:
\begin{itemize}
	\item very similar to the HPO definition
	\pause
	\item In practice, you want jointly optimize HPO and NAS~\lit{\href{https://ml.informatik.uni-freiburg.de/papers/18-AUTOML-EfficientNAS.pdf}{Zela et al. 2018}}
\end{itemize}

\end{frame}
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Per-Instance Algorithm Selection}

\begin{itemize}
	\item For solving the HPO, CASH and NAS problem, we use some kind of optimization approach to \alert{search} for a solution
	\pause
	\item A different view is: Can we learn from data and thus \alert{predict}\\ an algorithm/ hyperparameter configuration/ neural architecture?
\end{itemize}

\pause
\begin{block}{Definition}
	Let 
	\begin{itemize}
		\item $p(\dataset)$ be a probability \alert{distribution} over meta datasets $\dataset \in \mdata$,
		\pause
		\item $\algo \in \portfolio$ be a portfolio of algorithms, and
		\pause
		\item $\loss: \portfolio \times \mdata \rightarrow \perf$ be a loss metric   
	\end{itemize}
	
	\pause
	the \emph{per-instance algorithm selection problem} is to obtain a mapping 
	$s: \dataset \mapsto \algo$ 
	that optimizes 
	$$\argmin_{s} \int_{\mdata} \loss(s(\dataset),\dataset) p(\dataset) \diff\dataset$$
\end{block}

\end{frame}
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Algorithm Control}

\begin{itemize}
	\item So far, we assume that an algorithm runs with some given settings
	\item However, settings, such as learning rate, have to be adapted over time
\end{itemize}

\begin{block}{Definition}
	Let 
	\begin{itemize}
		\item $\pcs$ be a hyperparameter configuration of an algorithm $\algo$,
		\pause
		\item $p(\dataset)$ be a probability distribution over meta datasets $\dataset \in \mdata$,
		\pause
		\item $\stateRL_t$ be a state description of $\algo$ solving $\dataset$ at time point $t$,
		\pause
		\item $\loss: \policies \times \mdata \to \perf$ be a loss metric assessing the \alert{cost of a control policy $\pi \in \Pi$} on dataset $\dataset \in \mdata$
	\end{itemize}
	
	\pause
	the \emph{algorithm control problem} is to obtain a control policy $\policy^* : \stateRL_t \times \dataset \mapsto \conf$ by optimizing its loss across a distribution of datasets:
	\begin{equation}
	\pi^* \in \argmin_{\policy \in \policies} \int_{\mdata} p(\dataset) c(\policy, \dataset) \diff \dataset \nonumber
	\end{equation}
\end{block}

\end{frame}
%-----------------------------------------------------------------------	
%-----------------------------------------------------------------------	
%----------------------------------------------------------------------
\begin{frame}[c]{Overview}

\begin{description}
	\item[HPO] Search for the best hyperparameter configuration of a ML algorithm
	\item[CASH] Search for the best combination of algorithm and hyperparameter configuration
	\item[NAS] Search for the architecture of neural network
	\item[Selection] Predict the best algorithm (and its hyperparameter configuration)
	\item[Control] Predict the best hyperparameter configuration for algorithm state at a given time point 
\end{description}

\end{frame}
%-----------------------------------------------------------------------	
\end{document}
