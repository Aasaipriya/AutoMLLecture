\documentclass[10pt,a4paper]{article}
\usepackage{a4wide}
\usepackage[hyperfootnotes=false]{hyperref}


\input{macros}

\newcommand{\duedate}{24.02.19 (23:59 CET)}
\newcommand{\due}{{\bf This project is due on \duedate.} }

\usepackage{fancyhdr}
\pagestyle{fancy}

\fancyhf{}
\lhead{Due: \duedate}
\chead{{\bf\lecture}\\Final Project}
\rhead{\lectors\\ \semester}
\cfoot{Page \thepage}

\begin{document}
	\paragraph{The final project} is part of the oral exam, which means you are \textit{not allowed to work in groups}.
	The purpose of this project is that you get hands-on experience on most topics of the course and to show that you can present and explain the results of your work. 
	To this end, please submit your code, plots, tables etc. to a bitbucket repository to which at least one organizer of the lecture has access.\footnote{
	For bitbucket invite user \texttt{biedenka}.}

	In the first $15$ minutes of the exam, you will present your approach and the results such that we can discuss it together.
	It is important that \textit{your evaluation builds the basis for discussion and scientifically analyzes which are the important aspects and characteristics of your approach}---you should present your findings in a convincing manner.
	
	To give the project presentation some structure, you will have to prepare a few presentation slides.
	Your slides should consist of a motivation slide, slides detailing your approach (2-3) as well as slides for your results (2-3).
	You are allowed to submit at most 5 slides.
	\textit{Don't go overboard with your slides.}
	They are intended to make your presentation coherent.
	
	\section*{Optimization of a Convolutional Neural Network}
		
		You are tasked with the optimization and analysis of the performance of a neural network on the Kuzushiji-MNIST\footnote{\url{https://github.com/rois-codh/kmnist}} dataset(s).
		How you optimize the given network is up to you. 
		For example, you could optimize the hyperparameter of the networks optimizer, apply neural architecture search or a joint approach.
		In the end, you should convince us that you indeed improved the performance of the network when compared to a provided default configuration.
		To this end, you could consider the following tasks:
		
		\begin{itemize}
			\item Measure the default performance of the given network;
			\item Apply hyperparameter optimization or algorithm configuration to determine a well-performing configuration;
			\item Determine the importance of the algorithms parameters;
			\item Extend the configuration space to include preprocessing steps/dropout/skip connections/...;
			\item Use multi-fidelity optimization;
			\item Plot the confusion matrices;
			\item Plot the performance of automated algorithm design approaches over time; 
			\item Construct an EPM from observed data and predict well performing configurations;
			\item Use a learning to learn approach to learn how to optimize the network. 
		\end{itemize}
		\noindent
		Please note that you do not have to necessarily apply all these methods -- pick the ones that you think are most appropriate.
		We provide a repository (\url{https://bitbucket.org/biedenka/ml4aad_ws18_project}) for you to fork\footnote{\url{https://help.github.com/articles/fork-a-repo/}}, in which we will upload the following:
		\begin{itemize}
			\item A pytorch implementation to access the \textit{KMNIST} and \textit{K49} datasets
			\item A baseline parameterized network to optimize (also written in pytorch)
			\item An example script to show you how to train and evaluate an network based on the default configuration
		\end{itemize}
		
		You are allowed to use all scripts and tools you already know from the exercises; however, you are not limited to them.
		\newpage\noindent
		You should respect the following constraints:
		\begin{itemize}
			\item \textbf{Metric:}
			\begin{itemize}
				\item The final performance has to be measured in terms of classification accuracy.\\
					We require that you report your methods final performance on at least the \textit{KMNIST} dataset.
			\end{itemize}
			\item \textbf{Experimental Constraints:}
			\begin{itemize}
				\item Your code for making design decisions should run no longer than $86400$ seconds (without validation).
				\item Fully training a network can not train longer than 20 epochs.
				\item Your approach uses at most 16GB memory per CPU on the provided remote machines.
			\end{itemize}
			\item \textbf{Implementation Constraints:}
			\begin{itemize}
			  \item You can freely extend the baseline implementation provided to you. However, the code should always be able to run the given default network.
			  \item All changes to the network have to be (hyper-)parameterized in the given configuration space. You are not allowed to use manual tuning to achieve better performance. All improved design decisions have to be made (somehow) automatically.
			\end{itemize}
			\item \textbf{Grading Guidelines:}
			\begin{itemize}
			  \item The \textit{KMNIST} data set is by far easier than \textit{K49}. You can freely choose between these two datasets, but if you work only on \textit{KMNIST} you can achieve at best a $2.0$ as a grade for the project part.
			  \item The \textit{KMNIST} website\footnote{\url{https://github.com/rois-codh/kmnist}} provides some results of baseline implementations. We expect that you achieve an accuracy of at least $90\%$. You get bonus points by achieving better results close to the results on the homepage.
			\end{itemize}
		\end{itemize}
		
		We provide a Google spreadsheet\footnote{\url{https://docs.google.com/spreadsheets/d/1dVxWquJ0OXmZTHFQV0wrsNYPsCZdgcfjrlvaNtIBqRw/edit?usp=sharing}} in which you can upload your current progress. This sheet will not be monitored by us but gives you the opportunity to compare your results. This might help you identify early if your approach is working well or not.
\vspace*{\fill}\\
\noindent
\due Submit your presentation for the exam by sending a PDF of your slides to \texttt{biedenka@cs.uni-freiburg.de}. \textbf{No teams are allowed for the final project.}
\end{document}