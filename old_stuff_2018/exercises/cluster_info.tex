\documentclass{exam}
\usepackage{amsmath, amsfonts}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[super]{nth}
\usepackage{fancyvrb}
\usepackage{fvextra}

\DeclareMathOperator*{\argmin}{argmin}

\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}


\input{macros}
%\renewcommand{\hide}[1]{#1}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}

\pagestyle{headandfoot}

%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%
\newcommand{\duedate}{09.12.18 (14:00)}
\newcommand{\due}{{\bf This assignment is due on \duedate.} }
\firstpageheader
{\semester}
{{\bf\lecture}\\ Working with a Compute Cluster}
{\lectors}

\runningheader
{Due: \duedate}
{\assignment{8}}
{\semester}
%%%%%% MODIFY FOR EACH SHEET!!!! %%%%%%

\firstpagefooter
{}
{\thepage}
{}

\runningfooter
{}
{\thepage}
{}

\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}
	\noindent For exercise sheet 8, 9 as well as your final project, you are given access to a compute cluster.
	To help you work with a cluster running slurm\footnote{\url{https://slurm.schedmd.com/}} we provide you with a small example script and a list of useful
	commands.
	
	First off, to login to the cluster, you will have to login to the university network. From there you can ssh to the cluster using
	\verb|ssh kisbat1.rz.ki.privat|. The cluster is running Ubuntu 18.04.1.
	
	There you will have to clone your ML4AAD repo to work with your code. We suggest you setup a Miniconda\footnote{\url{https://conda.io/miniconda.html}} environment to install all necessary requirements.
	
	In the folder for exercise sheet 8 we will provide you the example script you can see below.
	\begin{Verbatim}[numbers=left,xleftmargin=5mm, breaklines,commandchars=\\\{\}]
#!/bin/bash
#SBATCH \textcolor{blue}{-p mlstudents_cpu-ivy} # partition/queue
#SBATCH \textcolor{blue}{--mem 4000} # memory pool for all cores (4GB)
#SBATCH \textcolor{blue}{-t 0-00:01} # time (D-HH:MM)
#SBATCH \textcolor{blue}{-c 1} # number of cores
#SBATCH -o log/%x.%N.%j.out # STDOUT
#SBATCH -e log/%x.%N.%j.err # STDERR
#SBATCH -J example-job # sets the job name
#SBATCH --mail-type=END,FAIL # (recive mails about end and timeouts/crashes)

# Print some information about the job to STDOUT
echo "Workingdir: $PWD";
echo "Started at $(date)";
echo "Running job $SLURM_JOB_NAME using $SLURM_JOB_CPUS_PER_NODE cpus per node with given JID $SLURM_JOB_ID on queue $SLURM_JOB_PARTITION";

# Job to perform
for i in {1..10000};
    do echo $RANDOM >> SomeRandomNumbers.txt;
done

# Print some Information about the endt-time to STDOUT
echo "DONE";
echo "Finished at $(date)";
	\end{Verbatim}
	Like the example file, every jobfile has to be started as shown in line 1 (\verb|#!/bin/bash|).\\
	
	\noindent
	After that, lines 2-9 handle the setup of the job itself. In line 2 the queue to which the job is to be submitted is specified
	(\texttt{mlstudents\_cpu-ivy}). You should only submit to this queue
	as you will be priority users for this queue. In total, this queue has 64 CPUs with 4GB of RAM per CPU available.\\
	
	\noindent
	Line 3-5 specifies the resources to be used for the job. Line 3 gives the amount of RAM (in MB) to use for each used CPU. Line 4 specifies the maximum
	allowed wallclock-time the job is allowed to use and line 5 gives the number of CPUs to use.\\
	
	\noindent
	Lines 6 \& 7 pipe the output of the job from STDOUT or STDERR to \texttt{log/JobName.HostName.JobID.(out/err)}\\
	
	\noindent
	In line 17-19 a very simple example job is specified that generates random numbers and writes them to a file. For your exercise(s) you could replace these lines
	by something such as \texttt{python file.py}. If you use a virtual environment you first would have to activate it before calling the python script itself.\\
	
	\noindent
	To submit your job to run on the cluster you can use \texttt{sbatch job.txt}
	If you want to run repeated versions of the same job (maybe running different seeds) you can use \texttt{sbatch --array=0-3\%2}. This will create an array job, consisting
	of 4 jobs (numbered 0, 1, 2, 3) of the same job file. \%2 makes sure that of all 4 jobs at most 2 will run simultaneously.\\
	
	\noindent
	To make sure your job is either successfully queued or already running you can use the command\\ \texttt{squeue -u \$USER}
	
	\noindent
	If you need to cancel your jobs you can use \texttt{scancel}. You can cancel jobs by ID (\texttt{scancel <jobid>}), name (\texttt{scancel --name <jobname>}) or all jobs belonging to a specific user (\texttt{scancel -u \$USER})
	
	\noindent
	For a detailed description of the sbatch command you can take a detailed look at \url{https://slurm.schedmd.com/sbatch.html}
	
\end{document}