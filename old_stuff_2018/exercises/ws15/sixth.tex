\documentclass{exam}
\usepackage{amsmath,amssymb,amsthm,mathrsfs,amsfonts,dsfont}
\usepackage{verbatim}
\usepackage{graphicx}


\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}
\renewcommand{\note}[1]{}
\newcommand{\hide}[1]{#1}
\renewcommand{\hide}[1]{}

\renewcommand{\vec}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmin}{argmin}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}

\pagestyle{headandfoot}
\firstpageheader{Due: 21.01.2016 (23:59 GMT)}{ {\bf MLOAD} \\ Sixth Assignment}{M. Lindauer \& F. Hutter\\ WS 2015/16}
\runningheader{Due: 21.12.2016 (23:59 GMT)}{Sixth Assignment}{WS 2015/16}
\runningfooter{}{}{}
\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}

After you now know how to use algorithm portfolios, for example in algorithm schedules
and algorithm selection, your next task is to implement some of the approaches discussed in the lecture 
on scenarios from the Algorithm Selection library (ASlib, \url{www.aslib.net}).  

\bigskip

For this exercise assignment, 
we provide two (simplified) scenarios from ASlib: \texttt{SAT11-INDU} and \texttt{SAT11-RAND}.
Each scenario consists of three files:
\begin{itemize}
  \item \texttt{algorithm\_runs.arff}: performance of each algorithm on each instance
  \item \texttt{feature\_values.arff}: instance features of each instance 
  \item \texttt{cv.arff}: cross-validation splits
\end{itemize}

We recommend to use the Python package \texttt{liac-arff} to read these files.

Both scenarios are runtime scenarios with a runtime cutoff ($\kappa$) of $5000$ seconds.
To simplify your tasks, we will ignore costs induced by using instance features.
Please note that some instance features can be missing -- you should use one of the functions provided by \texttt{sklearn} to impute these missing features (e.g., \texttt{sklearn.preprocessing.Imputer}).

\bigskip

All tasks include the submission of some results (besides the code).
To submit these results, please submit a PDF with all the results and your name(s).

\begin{questions}


\titledquestion{Single Best and Oracle Performance}[5]

Given an ASlib scenario, your task is to read the scenario files
and to compute the PAR$10$\footnote{PAR$10$ is the penalized average runtime where a timeout is counted as $10 \cdot \kappa$.} performance of the Single Best algorithm (SB) and the oracle performance.

The call of your implementation should be like:

\begin{verbatim}
python aslib_stats.py --algoruns algorithm_runs.arff
\end{verbatim}

and the output should be like:

\begin{verbatim}
Oracle: 1.0
SB: 2.0
\end{verbatim}

Please also report these values for both given scenarios ($\to$ PDF).

\titledquestion{Algorithm Schedules}[20 + 10 Bonus]

Since you already know stochastic local search (SLS) and you know how to compute the quality of an algorithm schedule,
your next task is to use SLS to find (a) a timeout-minimal time slice assignment and then (b) use SLS to find a time-minimal permutation of the algorithms with the time slices determined in (a), as discussed in the lecture.
You can use your favorite SLS technique (e.g, ILS or Tabu search). You can potentially reuse parts of your implementations from earlier exercises.
 
The call of your implementation should be like this:

\begin{verbatim}
python aslib_schedule.py --algoruns algorithm_runs.arff
\end{verbatim}

and the output should be like this:

\begin{verbatim}
assignment: {"algo1": 10, "algo2": 100}
permutation: ["algo2", "algo1"]
\end{verbatim}

The assignment should be represented as a dictionary that maps from algorithm name to a time slice.
You have to ensure that the time slices sum up to (at most) $\kappa = 5000$.
The permutation should be represented as a list that defines the order of the algorithms to execute.

You will get $0$ points if you return a solution that performs worse than the SB.
Please report your schedules and their performances ($\to$ PDF). 

As in the mini ML competition, the best three submissions will get again $10$ bonus points.
Your optimization should not run longer than $5$ minutes. 
Your program can output multiple solutions. 
We will consider only the last printed solution.

The ranking on each scenario will be according to PAR$10$,
and the final ranking will be according to the average ranking across both scenarios.

\titledquestion{Algorithm Selection}[25]

Your third task is to implement two of the presented algorithm selection approaches. You can choose between:

\begin{itemize}
  \item regression model for each algorithm,
  \item pairwise regression models to predict the performance difference,
  \item cost-sensitive pairwise classification with voting,
  \item clustering,
  \item and $k$-nearest neighbour.
\end{itemize} 

For the underlying machine learning techniques, you should use again \texttt{sklearn},
e.g., \texttt{sklearn.linear\_model.Ridge} for regression,
\texttt{sklearn.ensemble.RandomForestClassifier} for classification,
\texttt{sklearn.cluster.KMeans} for clustering
and \texttt{sklearn.neighbors.KNeighborsClassifier} for kNN.

To assess the performance of your algorithm selector,
you should use the provided cross-validation splits in cv.arff.
Accordingly, the call of your algorithm selector should look like this:

\begin{verbatim}
python aslib_selection.py --algoruns algorithm_runs.arff --features feature_values.arff\
 --cv cv.arff
\end{verbatim}

In the end, your algorithm selector should output the cross-validated PAR$10$ performance
and the selected algorithm on each instance in the following format:

\begin{verbatim}
PAR10 performance: 1.2345
Selection per instance:
instance1.cnf, algo2
instance2.cnf, algo3
instance3.cnf, algo1
...
\end{verbatim}

Please report the cross-validated performance ($\to$ PDF)
and how you handled the hyper-parameters of your approach.
We note that you will probably only get satisfactory results if you impute missing feature values (e.g., \texttt{sklearn.preprocessing.Imputer})
and scale the instance features\\ (e.g., \texttt{sklearn.preprocessing.MinMaxScaler}) -- depending on your used approach.

\titledquestion{Feedback}[Bonus: 5]
For each question in this assignment, state:
\begin{itemize}
	\item How long you worked on it.
	\item What you learned.
	\item Anything you would improve in this question if you were teaching the course.
\end{itemize}

\end{questions}


% {\bf This assignment is due on 16.11.2015 (23:59 GMT).} Submit your solution for the tasks by uploading a PDF to our ILIAS\footnote{ \url{https://ilias.uni-freiburg.de/goto.php?target=crs_465155&client_id=unifreiburg}.} course page. The PDF has to include the name of the submitter(s). Teams of at most $2$ students are allowed. Everyone has to submit his/her solution.\\

% Please note that this assignment is optional and you can get bonus points. However, we strongly encourage you to solve the given tasks since we will solve such CSP problems in the next exercise and you will benefit from some experience with modelling and understanding CSP problems. 

\noindent
{\bf This assignment is due on 21.01.2016 (23:59 GMT).} Submit your solution for the tasks by uploading an archive (tar.gz) to our ILIAS\footnote{ \url{https://ilias.uni-freiburg.de/goto.php?target=crs_465155&client_id=unifreiburg}.} course page. The archive has to include the name of the submitter(s). Teams of at most $2$ students are allowed. Everyone has to submit his/her solution. 

\bigskip
\paragraph{General constraints for code submissions}

\begin{itemize}
  \item The program can be called as stated on the exercise sheet.
  \item The program exactly returns the required output (neither less nor more) -- please use a \texttt{--verbose} option to increase the verbosity level for debugging.
  \item Your scripts should be commented to be readable for the tutors. All functions and classes are documented with a docstring. 
  \item Provide a README ($\to$ how to install requirements and run your program(s)) and (if necessary) an installation script if your program requires any other packages.
\end{itemize}

\bigskip

Submissions will get $0$ points if they do not satisfy these constraints.

\end{document}