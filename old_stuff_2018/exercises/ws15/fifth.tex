\documentclass{exam}
\usepackage{amsmath,amssymb,amsthm,mathrsfs,amsfonts,dsfont}
\usepackage{verbatim}
\usepackage{graphicx}


\usepackage[hyperfootnotes=false]{hyperref}

\usepackage[usenames,dvipsnames]{color}
\newcommand{\note}[1]{
	\noindent~\\
	\vspace{0.25cm}
	\fcolorbox{Red}{Orange}{\parbox{0.99\textwidth}{#1\\}}
	%{\parbox{0.99\textwidth}{#1\\}}
	\vspace{0.25cm}
}
\renewcommand{\note}[1]{}
\newcommand{\hide}[1]{#1}
\renewcommand{\hide}[1]{}

\renewcommand{\vec}[1]{\mathbf{#1}}
\DeclareMathOperator*{\argmin}{argmin}

\qformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}
\bonusqformat{\thequestion. \textbf{\thequestiontitle}\hfill[\thepoints]}

\pagestyle{headandfoot}
\firstpageheader{Due: 17.12.2015 (23:59 GMT)}{ {\bf MLOAD} \\ Fifth Assignment}{M. Lindauer \& F. Hutter\\ WS 2015/16}
\runningheader{Due: 17.12.2015 (23:59 GMT)}{Fifth Assignment}{WS 2015/16}
\runningfooter{}{}{}
\headrule
\pointsinrightmargin
\bracketedpoints
\marginpointname{pt.}


\begin{document}

After you now know how to analyze the performance of algorithms,
the goal of this fifth exercise is to let you analyze the performance of some machine learning algorithms
and your own SLS algorithms.

\bigskip

For this exercise assignment, 
we provide one machine learning data set for binary classification (one of the data sets from the last exercise).
You can download it at our ILIAS course website. To load it, as before, you can use already existing functions in \texttt{numpy}:\\
\texttt{numpy.loadtxt("x\_train.np")}

\bigskip

All tasks include the submission of some results (besides the code).
To submit these results, please submit a PDF with all the results and your name(s).

\begin{questions}


\titledquestion{Sampling distribution of the Z-Test}[10]

In the lecture, we used the fact that if each of $x_1, \dots, x_n$ is independently drawn from a Gaussian distribution $\mathcal{N}(\mu,\sigma^2)$, the distribution of their sample mean $\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$ of $n$ samples is distributed according to a Gaussian in turn. 
Derive the \emph{mean} $\mu_{\bar{x}} = \mathds{E}(\bar{x})$ and the \emph{variance} $\sigma^2_{\bar{x}} = Var(\bar{x})$ of that Gaussian.

\noindent
Hints:
\begin{itemize}
	\item $\mathds{E}(X+Y) = \mathds{E}(X) + \mathds{E}(Y)$
	\item $\mathds{E}(a \cdot X) = a \cdot \mathds{E}(X)$
	\item $Var(X+Y) = Var(X) + Var(Y)$
	\item $Var(a\cdot X) = a^2 \cdot Var(X)$
\end{itemize}

\hide{
Solution:\\
$\mathds{E}(\bar{x}) = \frac{1}{n} \sum_{i=1}^n \mathds{E}(x_i) = \frac{1}{n} \cdot n \cdot \mu = \mu$\\
$\to \mu_{\bar{x}} = \mu$\\

$Var(\bar{x}) = Var(\frac{1}{n} \sum_{i=1}^{n} x_i) = \frac{1}{n^2} Var(\sum_{i=1}^{n} x_i) = \frac{1}{n^2} \sum_{i=1}^{n} Var(x_i) = \frac{1}{n^2} \sum_{i=1}^{n} \sigma^2 = \frac{\sigma^2}{n} $\\
$\to \sigma^2_{\bar{x}} = \frac{\sigma^2}{n}$
}

\titledquestion{Analyzing random forests}[20]

In the lecture, we have seen the performance of stochastic gradient descent (SGD) as a function of the number of iterations.
Your task is to do a similar analysis for random forests on the given data set -- please use the \texttt{sklearn} package \texttt{sklearn.ensemble.RandomForestClassifier}.

In more detail, your task is to measure and analyze the performance of the random forest with

\begin{itemize}
  \item $100$ repetitions of the measurements;
  \item different numbers of trees (attribute \texttt{n\_estimators}) in the range [$1,20$] ($\to$ as a metric for the runtime of the random forest) -- you should use the option \texttt{warm\_start=True} to iteratively increase the number of trees;
  \item two different configurations
  \begin{enumerate}
    \item \texttt{criterion=``gini'', max\_features=``auto''}
    \item \texttt{criterion=``entropy'', max\_features=None}
  \end{enumerate}
\end{itemize} 

In the end, you should

\begin{itemize} 
  \item for each of the two configurations, plot mean performance and uncertainty bounds (i.e., standard deviation) on the training and the test as a function of the number of trees of ($\to$ PDF) [see Slide 33 in the lecture];
  \item plot the qualified runtime distributions of both configurations to reach an accuracy of $0.76$\\ ($\to$ PDF) [see Slide 34];
  \item apply an unpaired permutation test to determine whether one of the configurations reaches an accuracy of $0.76$ significantly faster (at a significance level of $\alpha=0.05$ and $10.000$ random permutations) ($\to$ PDF)
\end{itemize}

We recommend to use \texttt{matplotlib} to generate the plots.


\titledquestion{Analyzing your own stochastic local search (SLS) SAT solver}[20]

You have implemented stochastic local search (SLS) solvers for SAT solving in Task $2$ of the third exercise.\footnote{If your implementation returned wrong solutions, you should first fix that.}
Your task is now to measure the performance of your algorithms again, to analyze their performance in more detail.
To this end, we provide a new set of CNF instances (again in DIMACS format) -- see our ILIAS website for a download.

\begin{itemize}
  \item Measure the runtime of each of your SLS algorithms on each of the instances $20$ times with a runtime cutoff of $30$ CPU seconds;
  \item Plot the runtime distributions of your two algorithms on the sixth instance (\texttt{random\_ksat(6).dimacs}) [see Slide 8];
  \item Compute the average runtime for each instances across the repeated measurements and apply a paired permutation test to check whether one of your algorithms performs significantly better than the other one (at a significance level of $\alpha = 0.05$ and $10.000$ random permutations) across the instance set ($\to$ PDF);
  \begin{itemize}
    \item Report the p-value and whether you rejected $H_0$ or not 
  \end{itemize}
  \item Generate a scatter plot to compare your two algorithms on the average runtimes across the repetitions ($\to$ PDF) [see Slide 10] -- use the Python module we provide at ILIAS (\texttt{plot\_scatter.py});
  \item Generate a box plot with the runtime distributions of your two algorithms ($\to$ PDF) [see Slide 13];
  \item What do you learn from these plots ($\to$ PDF)? For example: 
  \begin{itemize}
    \item Does one of your algorithms perform better than the other one?
    \item Does one of your algorithms perform better on a specific type of instances (e.g., smaller instances)?
    \item Has the performance of one of your algorithms prominent outliers?
  \end{itemize}
\end{itemize}

To measure the runtime and to limit the maximal runtime, we recommend to use the the tool \texttt{runsolver} (version 3.3.5):
\url{http://www.cril.univ-artois.fr/~roussel/runsolver/}

\titledquestion{Feedback}[Bonus: 5]
For each question in this assignment, state:
\begin{itemize}
	\item How long you worked on it.
	\item What you learned.
	\item Anything you would improve in this question if you were teaching the course.
\end{itemize}

\end{questions}


% {\bf This assignment is due on 16.11.2015 (23:59 GMT).} Submit your solution for the tasks by uploading a PDF to our ILIAS\footnote{ \url{https://ilias.uni-freiburg.de/goto.php?target=crs_465155&client_id=unifreiburg}.} course page. The PDF has to include the name of the submitter(s). Teams of at most $2$ students are allowed. Everyone has to submit his/her solution.\\

% Please note that this assignment is optional and you can get bonus points. However, we strongly encourage you to solve the given tasks since we will solve such CSP problems in the next exercise and you will benefit from some experience with modelling and understanding CSP problems. 

\noindent
{\bf This assignment is due on 17.12.2015 (23:59 GMT).} Submit your solution for the tasks by uploading an archive (tar.gz) to our ILIAS\footnote{ \url{https://ilias.uni-freiburg.de/goto.php?target=crs_465155&client_id=unifreiburg}.} course page. The archive has to include the name of the submitter(s). Teams of at most $2$ students are allowed. Everyone has to submit his/her solution. 

\bigskip
\paragraph{General constraints for code submissions}

\begin{itemize}
  \item The program can be called as stated on the exercise sheet.
  \item The program exactly returns the required output (neither less nor more) -- please use a \texttt{--verbose} option to increase the verbosity level for debugging.
  \item Your scripts should be commented to be readable for the tutors. All functions and classes are documented with a docstring. 
  \item Provide a README ($\to$ how to install requirements and run your program(s)) and (if necessary) an installation script if your program requires any other packages.
\end{itemize}

\bigskip

Submissions will get $0$ points if they do not satisfy these constraints.

\end{document}