\input{t00_template.tex}
\subtitle{Wrap Up}


\begin{document}

\maketitle


%----------------------------------------------------------------------
%----------------------------------------------------------------------

\begin{frame}{From HPO to AutoML}
  So far we covered
  \begin{itemize}
    \item Mechanisms to select promising ML Algorithms for a Dataset (Algorithm Selection)
    \item HPO as Black-Box optimization
    \begin{itemize}
      \item Grid- and Random Search, Evolutionary Algorithms, Bayesian Optimization
    \end{itemize}
    \item HPO as a Grey-Box-Problem
    \begin{itemize}
      \item Hyperband, BOHB
    \end{itemize}
    \item Optimizing Neural Network Architectures (NAS)
    \begin{itemize}
      \item One-Shot Approaches, DART
    \end{itemize}
  \end{itemize}  
\end{frame}

\begin{frame}{From HPO to AutoML}
    \begin{center}
      \includegraphics[width = 0.9\linewidth]{images/drawing.pdf}  
    \end{center}
\end{frame}

\begin{frame}{Automate HPO}

  \begin{columns}
    \begin{column}{0.59\textwidth}

      For AutoML the user only supplies \ldots
      \begin{itemize}
        \item dataset
        \item performance measure and
        \item possibly a time limit
      \end{itemize}

      So far HPO additionally needs \ldots
      \begin{itemize}
        \item one learning algorithm (to generate Inducer $\inducer$),
        \item search space $\pcs$ to chose $\conf$ from,
        \item a resampling strategy to evaluate $\cost(\conf)$ and
        \item optimization algorithm.
      \end{itemize}

      To build an AutoML System we have to make these choices automatically.

    \end{column}%
    \begin{column}{0.4\textwidth}
      \begin{center}
        \includegraphics[width = \linewidth]{images/tuning.pdf}    
      \end{center}
    \end{column}
  \end{columns}

\end{frame}

\begin{frame}{Choice of learning algorithm}
  \begin{itemize}
    \item A good AutoML System should consider more than one learning algorithm. More on that later.
    \item A plethora of learning algorithm exists.
    \item Studies\footnote{\href{https://dl.acm.org/doi/10.5555/2627435.2697065}{Delgado et al., JMLR 2014}} and experience have shown that one representative of these categories usually reaches best performance (on tabular data):
    \begin{itemize}
      \item Penalized Regression, SVM, Gradient Boosting, Random Forests, Neural Networks
      \item (tuned) random forests hardly beaten by current AutoML frameworks\footnote{\href{https://arxiv.org/abs/1907.00909}{Gijsbers et al., 2019}}.
      \item Example: Auto-Sklearn 2.0\footnote{\href{https://arxiv.org/abs/2007.04074}{Feurer et al., 2020}} uses: Extra Trees, Gradient Boosting, Passive Aggressive, Random Forest, Linear Model
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Choice of Search Space for a Learning Algorithm}
  \begin{columns}
    \begin{column}{0.6\textwidth}
    Which hyperparameters should we consider for a given learning algorithm?
    \begin{itemize}
      \item Ranges often selected based on experience
      \begin{itemize}
        \item Compare to other AutoML Frameworks: e.g.\ Auto-Sklearn 2.0~\lit{\href{https://arxiv.org/abs/2007.04074}{Feurer et al., 2020}} 
      \end{itemize}
      \item Sensitivity analysis does not exist for each learning algorithm
      \item Solution: Analysis of previous HPO runs and learn mapping $\datasets \rightarrow \mathcal{P}(\pcs)$ is risky (leaving out important ranges) and complicated.
      \item Instead: Use big search space $\pcs$ and try to predict good initial design (e.g.\ for Bayesian Optimization).
    \end{itemize}
    \end{column}%
    \begin{column}{0.4\textwidth}
      \begin{center}
        \only<1>{
          \includegraphics[width = 0.8\linewidth]{images/probst2019jmlr_tab1.pdf}
        }
        \only<2>{
          \includegraphics[width = 0.8\linewidth]{images/probst2019jmlr_tab3.pdf}   
        }

        {\tiny Taken from \href{https://www.jmlr.org/papers/volume20/18-444/18-444.pdf}{Probst et al., 2019 JMLR}.}
      \end{center}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Choice of Resampling Strategy}
    \begin{itemize}
      \item Default: 10-fold CV
      \item Huge datasets: Holdout
      \item Tiny datasets: LOO
      \item For class imbalances:
      \begin{itemize}
        \item use stratification.
        \item ensure that validation split includes minority class.
      \end{itemize}
    \end{itemize}
    $\rightarrow$ Create heuristic or let the user decide.
\end{frame}

\begin{frame}{Choice of Optimization Algorithm}
  Choose optimization algorithm based on \ldots
  \begin{itemize}
    \item complexity of search space and
    \item estimated number of possible evaluations
  \end{itemize}

  \begin{itemize}
    \item Complex search space and many possible evaluations $\rightarrow$ Random Search, TPE, BO with RF as Surrogate
    \begin{itemize}
      \item Make use of Grey-Box Optimizers: Hyperband, BOHB
    \end{itemize}
    \item Simple search space and few possible Evaluations $\rightarrow$ BO with Kriging as Surrogate
    \begin{itemize}
      \item Grey-Box: BOHB
    \end{itemize}
    \item Complex search space and few possible evaluations $\rightarrow$ Use good defaults, Meta-Learning
    \item Deep Neural Network Architecture Search $\rightarrow$ NAS Algorithms and possibly HPO on found architecture
  \end{itemize}
\end{frame}



\begin{frame}[containsverbatim,allowframebreaks]{Preprocessing}
  \begin{center}
    \includegraphics[width = 0.5\linewidth]{images/AutoMLPipeline.jpg}  
  \end{center}

  Ideal ML Pipeline steps for AutoML Systems:
  \begin{itemize}
    \item Data Cleaning
    \item Feature Engineering
    \begin{itemize}
      \item Feature Selection
      \item Feature Preprocessing
      \item Feature Construction  
    \end{itemize}
  \end{itemize}

\end{frame}

\begin{frame}{Preprocessing not the strength of Non-commercial AutoML}
  \begin{columns}
    \begin{column}{0.6\textwidth}
      \vspace*{-1cm}
      \begin{center}
        \includegraphics[width = \linewidth]{images/Truong2019Towards_fig2.pdf}
      \end{center}
    \end{column}%
    \begin{column}{0.3\textwidth}
    \small
      Taken from \href{https://doi.org/10.1109/ICTAI.2019.00209}{Truong et al., 2019 ICTAI}.
      \vspace{1em}

      Highlighted: Non-commercial AutoML Frameworks
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}{Cleaning and Feature Selection}
    \begin{columns}
      \begin{column}{0.7\textwidth}

        Data Cleaning can hardly be automatized but a few heuristics exist:
        \begin{itemize}
          \item Remove ID Columns, Columns with mostly unique values
          \item Outlier detection (in the feature space)
          \item Detect time series or spatial data $\rightarrow$ randomized validation might be flawed.
        \end{itemize}

        Feature Selection
        \begin{itemize}
          \item Seldom increases performance but decreases computational costs $\rightarrow$ Multi-criteria optimization.
          \begin{itemize}
            \item Combined Feature Selection and HPO: \lit{\href{https://doi.org/10.1145/3377930.3389815}{Binder et al., 2020 GECCO}}
          \end{itemize}
          \item Happens indirectly in learning algorithm: random forest, lasso regression %FIXME More examples.
        \end{itemize}
      \end{column}%
      \begin{column}{0.3\textwidth}
        \begin{center}
          \includegraphics[width = \linewidth]{images/Binder2020multiobjective_fig3.pdf}

          {\tiny Taken from \href{https://doi.org/10.1145/3377930.3389815}{Binder et al., 2020 GECCO}.}
        \end{center}
      \end{column}
    \end{columns}
\end{frame}

\begin{frame}{Feature Preprocessing}
  \begin{itemize}
    \item Handling categorical values
    \begin{itemize}
      \item Impact Encoding (aka Target Encoding) \\
            Important: Target Encoding has to be obtained throgh CV / with regularization to prevent target leakage
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Feature Construction}
  \begin{itemize}
    \item Often not needed for DL/NAS.
    \item Generic:
    \begin{itemize}
      \item Polynomial Features
      \item Normalize 
      \item PCA
    \end{itemize}
    \item Heuristisc
    \begin{itemize}
      \item Detecting Dates, Hours: Transofrm to "circular" features within year, month, day, or whatever periodicity we assume \\
      e.g.\ $\tilde x_1 = sin(2\pi \cdot x /24)$ and $\tilde x_2 = cos(2\pi \cdot x /24)$
    \end{itemize}
    Combione with external data:
    \begin{itemize}
      \item Names $\leftarrow$ gender, ethnicity, age
      \item Home Adress $\leftarrow$ Household Income
      \item Location + Date $\leftarrow$ Weather
    \end{itemize}
  \end{itemize}
    
\end{frame}

\begin{frame}{Pipelining}
  
\end{frame}

\begin{frame}{Optimizing Pipelines}
  \begin{itemize}
    \item Pipelines represent hierarchical search space
  \end{itemize}

  Suitable optimizers:
  \begin{itemize}
    \item BO with RF surrogate
    \item Evolutionary Aproaches (similar to NAS)
  \end{itemize}
    
\end{frame}

\begin{frame}[containsverbatim,allowframebreaks]{Software}

\begin{itemize}
  \item DataRobot (comercial, gui)
  \item H20.ai (comercial but open source, r, python)
  \item TPOT, Tree-based Pipeline Optimization Tool  (2016-cont, open source, evolutionary approach) % show plot https://github.com/EpistasisLab/tpot
  \item AutoWEKA (2016, open source)
  \item mlr3automl (2020, prelim)
  \item Hyperopt-Sklearn (2014-cont) Only HPO
  \item Auto-Sklearn (2.0) (2015-cont) BO, ensembles, meta-learning
\end{itemize}

\end{frame}



\end{document}
