\input{t00_template.tex}

\usepackage[normalem]{ulem}
\usepackage{pifont}
\usepackage{relsize}
\renewcommand{\lit}[1]{{\smaller\color{black!60}[#1]}}
\subtitle{Practical Problems}


\begin{document}
	
	\maketitle
	
	\begin{frame}{Practical Problems: Stability}
		AutoML system should: 
		\begin{itemize}
			\item never fail to return a result
			\item terminate within a given time
			\item save intermediate results and allow to continue
		\end{itemize}
		
		\pause
		Failure points:
		\begin{itemize}
			\item optimizer can crash (e.g.\ GP in BO) 
			% $\longrightarrow$ return intermediate result, continue with warmstart / random search
			\item training can crash (e.g. segfault) 
			\item training of a single model can run "forever" 
			% \item prediction can crash $\longrightarrow$ use prediction of fallback learner
		\end{itemize}
		
		\pause
		Ways out:
		\begin{itemize}
			\item Encapsulate train/predict in separate process from HPO
			\item Ressource limit time and memory of that process by OS
			\item If learner crashes, run robust fallback (constant predictor)   
			\item Use "robust" HPO, run random config as last resort if proposal fails (exploration)
		\end{itemize}
		
	\end{frame}
	
	\begin{frame}{Practical Problems: Parallelization}
		Parallelization should allow:
		\begin{itemize}
			\item multiple cores
			\item multiple nodes 
		\end{itemize}
		
		Possible parallelization levels:
		\begin{itemize}
			\item training of learner (threading / GPU)
			\item resampling
			\item evaluations of configurations (batch proposal of HPO)
		\end{itemize}
		
		Possible problems:
		\begin{itemize}
			\item Sequential nature of HPO algorithms (e.g.\ BO)
			\item Heterogeneous runtimes cause idling $\longrightarrow$ 
			asynchronous HPO attractive, but more complex
			\item Main memory or CPU-cache becomes bottleneck
			\item Communication between workers
		\end{itemize}
		
	\end{frame}
	
	
\end{document}
