{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duration = [4.5, 4, 1, 8, 4, 4.5, 6]\n",
    "with plt.xkcd():\n",
    "    plt.boxplot(duration)\n",
    "    plt.title(\"Time taken to do this exercise\")\n",
    "    plt.ylabel(\"hours\")\n",
    "    plt.xticks([1,], [\"you\", ])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = \"./PERFORMANCEMATRIX/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2 = 269 # 254\n",
    "id1 = 336\n",
    "\n",
    "loss_dc1 = {}\n",
    "for fl in glob.glob(\"%s/%s_*\" % (dir_, id1)):\n",
    "    with open(fl, \"r\") as fh:\n",
    "        line = fh.readlines()[0]\n",
    "        line = json.loads(line)\n",
    "        loss_dc1[line[\"run_on\"]] = line[\"loss\"]\n",
    "\n",
    "loss_dc2 = {}\n",
    "for fl in glob.glob(\"%s/%s_*\" % (dir_, id2)):\n",
    "    with open(fl, \"r\") as fh:\n",
    "        line = fh.readlines()[0]\n",
    "        line = json.loads(line)\n",
    "        loss_dc2[line[\"run_on\"]] = line[\"loss\"]\n",
    "        \n",
    "data_ids = list(loss_dc1.keys())\n",
    "data_ids = np.sort(data_ids)\n",
    "\n",
    "y1 = [loss_dc1[i] for i in data_ids]\n",
    "y2 = [loss_dc2[i] for i in data_ids]\n",
    "y1 = np.array(y1)\n",
    "y2 = np.array(y2)\n",
    "\n",
    "print(\"A: Mean, std: %g +- %g\" % (np.mean(y1), np.std(y1)))\n",
    "print(\"A: Quartiles: %f, %f, %f\" % (np.percentile(y1, 25),\n",
    "                                    np.percentile(y1, 50),\n",
    "                                    np.percentile(y1, 75)))\n",
    "print(\"B: Mean, std: %g +- %g\" % (np.mean(y2), np.std(y2)))\n",
    "print(\"B: Quartiles: %f, %f, %f\" % (np.percentile(y2, 25),\n",
    "                                    np.percentile(y2, 50), \n",
    "                                    np.percentile(y2, 75)))\n",
    "#np.savetxt(\"data.csv\", np.vstack([y1, y2]).T, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot\n",
    "thresh = 0.1\n",
    "idx1 = (y1 > y2+thresh)\n",
    "plt.scatter(y1[idx1], y2[idx1], label=\"B is better\")\n",
    "print(\"A is better than B on %d datasets\" % np.sum(idx1))\n",
    "\n",
    "\n",
    "idx2 = (y2 > y1+thresh)\n",
    "plt.scatter(y1[idx2], y2[idx2], label=\"A is better\")\n",
    "print(\"B is better than A on %d datasets\" % np.sum(idx2))\n",
    "\n",
    "plt.scatter(y1, y2, marker=\"+\", zorder=0, label=\"equal\")\n",
    "print(\"A and B perform comparable on %d datasets\" % (y1.shape[0] - np.sum(idx1) - np.sum(idx2)))\n",
    "plt.plot([0, 1], [0,1], c='k', zorder=0)\n",
    "plt.plot([0, 1-thresh], [thresh, 1], c='k', linestyle=\":\", zorder=0)\n",
    "plt.plot([thresh, 1], [0, 1-thresh], c='k', linestyle=\":\", zorder=0)\n",
    "plt.xlabel(\"Error of A\")\n",
    "plt.ylabel(\"Error of B\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eCDF\n",
    "plt.step(np.sort(y1[::10]), np.arange(1, len(y1[::10])+1) / (len(y1[::10])+1), label=\"A\")\n",
    "plt.step(np.sort(y2[::10]), np.arange(1, len(y2[::10])+1) / (len(y2[::10])+1), label=\"B\")\n",
    "\n",
    "plt.step(np.sort(y1[::10]), np.arange(len(y1[::10])) / (len(y1[::10])), label=\"A\")\n",
    "plt.step(np.sort(y2[::10]), np.arange(len(y2[::10])) / (len(y2[::10])), label=\"B\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Error\")\n",
    "plt.ylabel(\"P(X<L)\")\n",
    "plt.plot([0.4, 0.4], [1, 0], c='k', zorder=0, linestyle=\":\")\n",
    "plt.show()\n",
    "frac = np.sum(y1 <= 0.4)/len(y1)\n",
    "print(\"Probability of A to achieve an error lower than 0.4: %f\" % frac)\n",
    "frac = np.sum(y2 <= 0.4)/len(y2)\n",
    "print(\"Probability of B to achieve an error lower than 0.4: %f\" % frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot and violin plot\n",
    "# See also https://matplotlib.org/gallery/statistics/boxplot_vs_violin.html\n",
    "plt.boxplot([y1, y2], labels=[\"A\", \"B\"])\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.show()\n",
    "\n",
    "plt.violinplot([y1, y2])\n",
    "plt.xticks([1, 2], [\"A\", \"B\"])\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired Permutation test\n",
    "print(\"H_0: A and B have equal means\")\n",
    "print(\"H_1: The mean of A is better (smaller) than that of B\")\n",
    "\n",
    "t = np.mean(y1) - np.mean(y2)\n",
    "print(\"Test statistic t: %f\" % t)\n",
    "rng = np.random.RandomState(1)\n",
    "s = []\n",
    "for i in range(10000):\n",
    "    ind_dataset1 = []\n",
    "    ind_dataset2 = []\n",
    "    for i,j in zip(y1, y2):\n",
    "        if rng.random_sample() > 0.5:\n",
    "            ind_dataset1.append(i)\n",
    "            ind_dataset2.append(j)\n",
    "        else:\n",
    "            ind_dataset1.append(j)\n",
    "            ind_dataset2.append(i)\n",
    "    m1 = np.mean(ind_dataset1)\n",
    "    m2 = np.mean(ind_dataset2)\n",
    "    s.append(m1-m2)\n",
    "s = np.array(s)\n",
    "\n",
    "print(\"Samples with s<t: %d (of %d)\" % (np.sum(s<t), len(s)))\n",
    "p = np.sum(s<t)/len(s)\n",
    "print(\"Then, p-value %f < alpha?\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired Permutation test, other alternative hypothesis\n",
    "\n",
    "print(\"H_0: A and B have equal means\")\n",
    "print(\"H_1: The mean of B is better (smaller) than that of A\")\n",
    "\n",
    "t = np.mean(y2) - np.mean(y1)\n",
    "print(\"Test statistic t: %f\" % t)\n",
    "rng = np.random.RandomState(1)\n",
    "s = []\n",
    "for i in range(10000):\n",
    "    ind_dataset1 = []\n",
    "    ind_dataset2 = []\n",
    "    for i,j in zip(y2, y1):\n",
    "        if rng.random_sample() > 0.5:\n",
    "            ind_dataset1.append(i)\n",
    "            ind_dataset2.append(j)\n",
    "        else:\n",
    "            ind_dataset1.append(j)\n",
    "            ind_dataset2.append(i)\n",
    "    m1 = np.mean(ind_dataset1)\n",
    "    m2 = np.mean(ind_dataset2)\n",
    "    s.append(m2-m1)\n",
    "s = np.array(s)\n",
    "\n",
    "plt.hist(s)\n",
    "plt.title(\"Distribution of test statistics\")\n",
    "plt.ylabel(\"number of permutations\")\n",
    "plt.xlabel(\"m1 - m2\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Samples with s<t: %d (of %d)\" % (np.sum(s<t), len(s)))\n",
    "p = np.sum(s<t)/len(s)\n",
    "print(\"Then, p-value %f < alpha?\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paired Permutation test, other alternative hypothesis\n",
    "print(\"H_0: A and B have equal means\")\n",
    "print(\"H_1: The mean of B is better/worse (smaller/higher) than that of A\")\n",
    "\n",
    "t = np.abs(np.mean(y2) - np.mean(y1))\n",
    "print(\"Test statistic t: %f\" % t)\n",
    "rng = np.random.RandomState(1)\n",
    "s = []\n",
    "for i in range(10000):\n",
    "    ind_dataset1 = []\n",
    "    ind_dataset2 = []\n",
    "    for i,j in zip(y2, y1):\n",
    "        if rng.random_sample() > 0.5:\n",
    "            ind_dataset1.append(i)\n",
    "            ind_dataset2.append(j)\n",
    "        else:\n",
    "            ind_dataset1.append(j)\n",
    "            ind_dataset2.append(i)\n",
    "    m1 = np.mean(ind_dataset1)\n",
    "    m2 = np.mean(ind_dataset2)\n",
    "    s.append(np.abs(m2-m1))\n",
    "s = np.array(s)\n",
    "\n",
    "plt.hist(s)\n",
    "plt.title(\"Distribution of test statistics\")\n",
    "plt.ylabel(\"number of permutations\")\n",
    "plt.xlabel(\"m1 - m2\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Samples with s<t: %d (of %d)\" % (np.sum(s<t), len(s)))\n",
    "p = np.sum(s<t)/len(s)\n",
    "print(\"Then, p-value %f < alpha?\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permutation test (non-paired)\n",
    "t = np.mean(y1) - np.mean(y2)\n",
    "print(\"Test statistic t: %f\" % t)\n",
    "rng = np.random.RandomState(1)\n",
    "s = []\n",
    "for i in range(10000):\n",
    "    ind_dataset = np.hstack([y1, y2])\n",
    "    rng.shuffle(ind_dataset)\n",
    "    m1 = np.mean(ind_dataset[:len(y1)])\n",
    "    m2 = np.mean(ind_dataset[-len(y2):])\n",
    "    s.append(m1-m2)\n",
    "plt.hist(s)\n",
    "plt.title(\"Distribution of test statistics\")\n",
    "plt.ylabel(\"number of permutations\")\n",
    "plt.xlabel(\"m1 - m2\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Samples with s<t: %d (of %d)\" % (np.sum(s<t), len(s)))\n",
    "p = np.sum(s<t)/len(s)\n",
    "print(\"Then, p-value %f < alpha?\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative implementation, not needed\n",
    "\n",
    "# data shape: string index, float performance data\n",
    "n_points = len(y1)\n",
    "\n",
    "# convert data to numpy array\n",
    "data = np.vstack([y1, y2]).T\n",
    "#print(data.shape)\n",
    "# data[:, 1] += np.random.normal(loc=0, scale=1, size=(n_points,))\n",
    "\n",
    "# compute original test statistics\n",
    "test_stat = np.mean(y1) - np.mean(y2)\n",
    "#print(test_stat)\n",
    "# permutate columns in the data and compute test statistics for each\n",
    "# permutation\n",
    "runs = 1000\n",
    "stats = []\n",
    "for r in range(runs):\n",
    "   perm = np.apply_along_axis(np.random.permutation, 1, data)\n",
    "   test_stat_perm = np.mean(perm[:, 0]) - np.mean(perm[:, 1])\n",
    "   stats.append(test_stat_perm)\n",
    "\n",
    "# p value is now how many of those test statistcs are smaller than the\n",
    "# original (not permutated) test statistics\n",
    "# for equal means, this should be about 0.5\n",
    "s_set = np.array(stats)\n",
    "p_value = np.sum(s_set < test_stat) / runs\n",
    "print(p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
